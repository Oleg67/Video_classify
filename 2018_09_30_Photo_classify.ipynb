{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.5\n",
      "3.4.1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import imageio\n",
    "print np.__version__\n",
    "print cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_imagesPath(folder):\n",
    "    \"\"\"\n",
    "    create a list of all images' paths  for all subfolders in the folder\n",
    "    \"\"\"\n",
    "\n",
    "    fd_list = []\n",
    "    \n",
    "    if not all_dir(folder):\n",
    "        return sorted(map(lambda x: os.path.join(folder, x), os.listdir(folder)))\n",
    "    \n",
    "    for fd in os.listdir(folder):\n",
    "        path = os.path.join(os.getcwd(), folder, fd)\n",
    "        fd_list += get_list_of_imagesPath(path)\n",
    "\n",
    "    return fd_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_dir(folder):\n",
    "    \"\"\"\n",
    "    serve to check all filenames in folder is dir\n",
    "    \"\"\"\n",
    "    flag = True\n",
    "    for fd in os.listdir(folder):\n",
    "        flag = True and os.path.isdir(os.path.join(folder,fd))\n",
    "        \n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def copy_files_to_folder(list_files, folder):\n",
    "    \"\"\"\n",
    "    copy the list of files in the folder\n",
    "    \"\"\"\n",
    "    # check the existing of the folder if not make\n",
    "    if not os.path.exists(os.path.join(os.getcwd(),folder)):\n",
    "        os.makedirs(os.path.join(os.getcwd(), folder))\n",
    "    \n",
    "    for f in list_files:\n",
    "        shutil.copyfile(f , os.path.join(os.getcwd(), folder, f.split('/')[-1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Folders_for_train_test(folder, test_size=0.15):\n",
    "    \"\"\"\n",
    "    seperate images on train and test foldes \n",
    "    list images - list of image' paths \n",
    "    test_size is the size of the test folder \n",
    "    \"\"\"\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    \n",
    "    list_images = np.array(get_list_of_imagesPath(folder))\n",
    "    y = np.vectorize(lambda x: x.split('/')[-3])(list_images)\n",
    "    \n",
    "    images_train, images_test, y_train, y_test = train_test_split(list_images, y, stratify=y, test_size=test_size)\n",
    "    \n",
    "    for fd, img, y in zip(['train', 'test'], (images_train, images_test), (y_train, y_test)):\n",
    "        for lable in np.unique(y):\n",
    "            copy_files_to_folder(img[y == lable], os.path.join(folder, fd, lable))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = 'new_224_112_filter_1'\n",
    "create_Folders_for_train_test(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image_size(folder, add_folder='train'):\n",
    "    \"\"\"\n",
    "    return the size of images in the folder\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if add_folder:\n",
    "            path = os.path.join(os.getcwd(), folder, add_folder)\n",
    "        else:\n",
    "            path = os.path.join(os.getcwd(), folder)\n",
    "        \n",
    "        while os.path.isdir(path):\n",
    "            filename = os.listdir(path)[0]\n",
    "            path = os.path.join(path, filename)\n",
    "            print path\n",
    "            \n",
    "    except OSError as e:\n",
    "        print e\n",
    "        return\n",
    "\n",
    "    return imageio.imread(path).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/oleg/EnkeSystem/new_224_112_filter_1/train/video_bad\n",
      "/home/oleg/EnkeSystem/new_224_112_filter_1/train/video_bad/08841_image.jpg\n"
     ]
    }
   ],
   "source": [
    "size = get_image_size(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, (112, 224))"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(size), size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oleg/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#libraries\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gerator of the train set\n",
    "datagen_tr = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #samplewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    #samplewise_std_normalization=True,\n",
    "    #rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    #rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['video_bad', 'video_good']"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join(os.getcwd(), FOLDER, 'train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/oleg/EnkeSystem/new_224_112_filter/train'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(os.getcwd(), 'new_224_112_filter', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22671 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# train generator\n",
    "train_generator = datagen_tr.flow_from_directory(\n",
    "    os.path.join(os.getcwd(), FOLDER, 'train'),\n",
    "    \n",
    "    target_size=size,\n",
    "    color_mode='grayscale',\n",
    "    classes=None,\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    save_prefix='',\n",
    "    save_format='png',\n",
    "    follow_links=False,\n",
    "    interpolation='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generator of the test set\n",
    "datagen_ts = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #samplewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    #samplewise_std_normalization=True,\n",
    "    #rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    #rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4528 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# test generator\n",
    "test_generator = datagen_ts.flow_from_directory(\n",
    "    os.path.join(os.getcwd(), FOLDER, 'test'),\n",
    "    \n",
    "    target_size=size,\n",
    "    color_mode='grayscale',\n",
    "    classes=None,\n",
    "    class_mode='binary',\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    save_prefix='',\n",
    "    save_format='png',\n",
    "    follow_links=False,\n",
    "    interpolation='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 112, 224, 2)       20        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 56, 112, 2)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 112, 4)        76        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 28, 56, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 56, 8)         296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 14, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 28, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 7, 14, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 7, 14, 16)         1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 3, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 336)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                10784     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 12,961\n",
      "Trainable params: 12,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#num_classes = 1\n",
    "epochs = 100\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "#model.add(tf.keras.layers.BatchNormalization( input_shape=(112,224,1)))\n",
    "#model.add(tf.keras.layers.Conv2D(2, (3,3), activation='relu',padding='same'))\n",
    "model.add(tf.keras.layers.Conv2D(2, (3,3), \n",
    "                 activation='relu',\n",
    "                padding='same',\n",
    "                input_shape=(112,224,1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Conv2D(4, 3, activation='relu', padding='same'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Conv2D(8, (3,3), activation='relu', padding='same'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Conv2D(8, (3,3), activation='relu', padding='same'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "#model.add(tf.keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "#model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "#model.add(tf.keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "#model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "#model.add(tf.keras.layers.Dense(512, activation='relu'))#\n",
    "#model.add(tf.keras.layers.Dropout(0.5))\n",
    "#model.add(tf.keras.layers.Dense(122, activation='relu'))\n",
    "#model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(lr=1e-3, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 57s - loss: 0.8640 - acc: 0.5788 - val_loss: 0.6888 - val_acc: 0.5250\n",
      "Epoch 2/50\n",
      " - 57s - loss: 0.6611 - acc: 0.6081 - val_loss: 0.6837 - val_acc: 0.5644\n",
      "Epoch 3/50\n",
      " - 56s - loss: 0.6309 - acc: 0.6472 - val_loss: 0.6208 - val_acc: 0.6381\n",
      "Epoch 4/50\n",
      " - 57s - loss: 0.5961 - acc: 0.6748 - val_loss: 0.5712 - val_acc: 0.7081\n",
      "Epoch 5/50\n",
      " - 57s - loss: 0.5466 - acc: 0.7262 - val_loss: 0.5304 - val_acc: 0.7488\n",
      "Epoch 6/50\n",
      " - 57s - loss: 0.5114 - acc: 0.7576 - val_loss: 0.4940 - val_acc: 0.7588\n",
      "Epoch 7/50\n",
      " - 59s - loss: 0.4935 - acc: 0.7670 - val_loss: 0.4708 - val_acc: 0.7837\n",
      "Epoch 8/50\n",
      " - 58s - loss: 0.4799 - acc: 0.7695 - val_loss: 0.4776 - val_acc: 0.7688\n",
      "Epoch 9/50\n",
      " - 57s - loss: 0.4566 - acc: 0.7862 - val_loss: 0.4508 - val_acc: 0.7963\n",
      "Epoch 10/50\n",
      " - 57s - loss: 0.4481 - acc: 0.7907 - val_loss: 0.4465 - val_acc: 0.7925\n",
      "Epoch 11/50\n",
      " - 58s - loss: 0.4294 - acc: 0.8002 - val_loss: 0.4076 - val_acc: 0.8150\n",
      "Epoch 12/50\n",
      " - 57s - loss: 0.4155 - acc: 0.8060 - val_loss: 0.4133 - val_acc: 0.7956\n",
      "Epoch 13/50\n",
      " - 57s - loss: 0.4100 - acc: 0.8093 - val_loss: 0.4001 - val_acc: 0.8131\n",
      "Epoch 14/50\n",
      " - 58s - loss: 0.4055 - acc: 0.8106 - val_loss: 0.3827 - val_acc: 0.8237\n",
      "Epoch 15/50\n",
      " - 57s - loss: 0.3953 - acc: 0.8190 - val_loss: 0.3712 - val_acc: 0.8287\n",
      "Epoch 16/50\n",
      " - 58s - loss: 0.3901 - acc: 0.8157 - val_loss: 0.3784 - val_acc: 0.8200\n",
      "Epoch 17/50\n",
      " - 59s - loss: 0.3935 - acc: 0.8152 - val_loss: 0.3731 - val_acc: 0.8287\n",
      "Epoch 18/50\n",
      " - 58s - loss: 0.3818 - acc: 0.8224 - val_loss: 0.3606 - val_acc: 0.8356\n",
      "Epoch 19/50\n",
      " - 58s - loss: 0.3875 - acc: 0.8191 - val_loss: 0.3688 - val_acc: 0.8306\n",
      "Epoch 20/50\n",
      " - 58s - loss: 0.3750 - acc: 0.8271 - val_loss: 0.3707 - val_acc: 0.8319\n",
      "Epoch 21/50\n",
      " - 58s - loss: 0.3661 - acc: 0.8309 - val_loss: 0.3816 - val_acc: 0.8256\n",
      "Epoch 22/50\n",
      " - 59s - loss: 0.3655 - acc: 0.8322 - val_loss: 0.3415 - val_acc: 0.8462\n",
      "Epoch 23/50\n",
      " - 60s - loss: 0.3685 - acc: 0.8327 - val_loss: 0.3598 - val_acc: 0.8394\n",
      "Epoch 24/50\n",
      " - 61s - loss: 0.3579 - acc: 0.8349 - val_loss: 0.3186 - val_acc: 0.8581\n",
      "Epoch 25/50\n",
      " - 61s - loss: 0.3568 - acc: 0.8368 - val_loss: 0.3563 - val_acc: 0.8263\n",
      "Epoch 26/50\n",
      " - 60s - loss: 0.3540 - acc: 0.8387 - val_loss: 0.3374 - val_acc: 0.8481\n",
      "Epoch 27/50\n",
      " - 59s - loss: 0.3516 - acc: 0.8415 - val_loss: 0.3388 - val_acc: 0.8438\n",
      "Epoch 28/50\n",
      " - 57s - loss: 0.3407 - acc: 0.8445 - val_loss: 0.3356 - val_acc: 0.8363\n",
      "Epoch 29/50\n",
      " - 58s - loss: 0.3464 - acc: 0.8447 - val_loss: 0.3399 - val_acc: 0.8400\n",
      "Epoch 30/50\n",
      " - 58s - loss: 0.3448 - acc: 0.8416 - val_loss: 0.3243 - val_acc: 0.8413\n",
      "Epoch 31/50\n",
      " - 59s - loss: 0.3434 - acc: 0.8467 - val_loss: 0.3227 - val_acc: 0.8488\n",
      "Epoch 32/50\n",
      " - 58s - loss: 0.3391 - acc: 0.8436 - val_loss: 0.3114 - val_acc: 0.8600\n",
      "Epoch 33/50\n",
      " - 58s - loss: 0.3396 - acc: 0.8433 - val_loss: 0.3191 - val_acc: 0.8612\n",
      "Epoch 34/50\n",
      " - 58s - loss: 0.3352 - acc: 0.8438 - val_loss: 0.3431 - val_acc: 0.8381\n",
      "Epoch 35/50\n",
      " - 57s - loss: 0.3368 - acc: 0.8448 - val_loss: 0.2965 - val_acc: 0.8612\n",
      "Epoch 36/50\n",
      " - 57s - loss: 0.3311 - acc: 0.8472 - val_loss: 0.3106 - val_acc: 0.8550\n",
      "Epoch 37/50\n",
      " - 57s - loss: 0.3348 - acc: 0.8464 - val_loss: 0.3357 - val_acc: 0.8450\n",
      "Epoch 38/50\n",
      " - 57s - loss: 0.3297 - acc: 0.8507 - val_loss: 0.2956 - val_acc: 0.8612\n",
      "Epoch 39/50\n",
      " - 57s - loss: 0.3306 - acc: 0.8494 - val_loss: 0.3306 - val_acc: 0.8413\n",
      "Epoch 40/50\n",
      " - 57s - loss: 0.3284 - acc: 0.8546 - val_loss: 0.2923 - val_acc: 0.8638\n",
      "Epoch 41/50\n",
      " - 57s - loss: 0.3262 - acc: 0.8471 - val_loss: 0.2862 - val_acc: 0.8731\n",
      "Epoch 42/50\n",
      " - 57s - loss: 0.3223 - acc: 0.8546 - val_loss: 0.3482 - val_acc: 0.8394\n",
      "Epoch 43/50\n",
      " - 57s - loss: 0.3253 - acc: 0.8505 - val_loss: 0.3325 - val_acc: 0.8506\n",
      "Epoch 44/50\n",
      " - 57s - loss: 0.3213 - acc: 0.8571 - val_loss: 0.2911 - val_acc: 0.8662\n",
      "Epoch 45/50\n",
      " - 58s - loss: 0.3200 - acc: 0.8546 - val_loss: 0.3384 - val_acc: 0.8488\n",
      "Epoch 46/50\n",
      " - 57s - loss: 0.3151 - acc: 0.8593 - val_loss: 0.3383 - val_acc: 0.8512\n",
      "Epoch 47/50\n",
      " - 56s - loss: 0.3158 - acc: 0.8565 - val_loss: 0.2978 - val_acc: 0.8638\n",
      "Epoch 48/50\n",
      " - 56s - loss: 0.3152 - acc: 0.8604 - val_loss: 0.3131 - val_acc: 0.8650\n",
      "Epoch 49/50\n",
      " - 57s - loss: 0.3235 - acc: 0.8544 - val_loss: 0.3193 - val_acc: 0.8644\n",
      "Epoch 50/50\n",
      " - 56s - loss: 0.3175 - acc: 0.8578 - val_loss: 0.3225 - val_acc: 0.8550\n"
     ]
    }
   ],
   "source": [
    "callbacks = [ tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0)\n",
    "             #, ModelCheckpoint('video_3_512_VGG_no_drop.h5', monitor='val_loss', save_best_only=True, verbose=0) \n",
    "            ]\n",
    "with tf.device('/gpu:0'):\n",
    "    model.fit_generator(train_generator, workers=-1, \n",
    "                    steps_per_epoch=400, \n",
    "                    epochs=50, \n",
    "                    verbose=2,\n",
    "                    #callbacks=callbacks,\n",
    "                    use_multiprocessing=True,\n",
    "                    validation_data=test_generator,\n",
    "                    validation_steps=100\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network building 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_4 (Batch (None, 112, 224, 1)       4         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 112, 224, 2)       20        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 56, 112, 2)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 56, 112, 4)        76        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 28, 56, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 28, 56, 8)         296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 14, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 14, 28, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 7, 14, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 7, 14, 16)         1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 3, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 3, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 336)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 44)                14828     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 44)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                1440      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 18,449\n",
      "Trainable params: 18,447\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#num_classes = 1\n",
    "epochs = 100\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.BatchNormalization(input_shape=(112,224,1)))\n",
    "model.add(tf.keras.layers.Conv2D(2, (3,3), activation='relu',padding='same'))\n",
    "#model.add(tf.keras.layers.Conv2D(2, (3,3), \n",
    "#                 activation='relu',\n",
    "#                padding='same',\n",
    "#                input_shape=(112,224,1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Conv2D(4, 3, activation='relu', padding='same'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Conv2D(8, (3,3), activation='relu', padding='same'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Conv2D(8, (3,3), activation='relu', padding='same'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "#model.add(tf.keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "#model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "#model.add(tf.keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "#model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "#model.add(tf.keras.layers.Dense(512, activation='relu'))#\n",
    "#model.add(tf.keras.layers.Dropout(0.5))\n",
    "#model.add(tf.keras.layers.Dense(122, activation='relu'))\n",
    "#model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(44, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(lr=1e-3, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 69s - loss: 0.6707 - acc: 0.6020 - val_loss: 0.6891 - val_acc: 0.5513\n",
      "Epoch 2/50\n",
      " - 68s - loss: 0.5749 - acc: 0.6964 - val_loss: 0.5057 - val_acc: 0.7569\n",
      "Epoch 3/50\n",
      " - 69s - loss: 0.4918 - acc: 0.7681 - val_loss: 0.4483 - val_acc: 0.7944\n",
      "Epoch 4/50\n",
      " - 68s - loss: 0.4490 - acc: 0.7880 - val_loss: 0.4467 - val_acc: 0.7863\n",
      "Epoch 5/50\n",
      " - 68s - loss: 0.4356 - acc: 0.7992 - val_loss: 0.4094 - val_acc: 0.8131\n",
      "Epoch 6/50\n",
      " - 67s - loss: 0.4131 - acc: 0.8094 - val_loss: 0.3946 - val_acc: 0.8219\n",
      "Epoch 7/50\n",
      " - 68s - loss: 0.3997 - acc: 0.8209 - val_loss: 0.3798 - val_acc: 0.8363\n",
      "Epoch 8/50\n",
      " - 67s - loss: 0.3947 - acc: 0.8187 - val_loss: 0.3932 - val_acc: 0.8287\n",
      "Epoch 9/50\n",
      " - 67s - loss: 0.3911 - acc: 0.8231 - val_loss: 0.3901 - val_acc: 0.8263\n",
      "Epoch 10/50\n",
      " - 68s - loss: 0.3820 - acc: 0.8281 - val_loss: 0.3567 - val_acc: 0.8450\n",
      "Epoch 11/50\n",
      " - 69s - loss: 0.3721 - acc: 0.8341 - val_loss: 0.3591 - val_acc: 0.8350\n",
      "Epoch 12/50\n",
      " - 69s - loss: 0.3692 - acc: 0.8332 - val_loss: 0.3652 - val_acc: 0.8419\n",
      "Epoch 13/50\n",
      " - 68s - loss: 0.3614 - acc: 0.8340 - val_loss: 0.3576 - val_acc: 0.8369\n",
      "Epoch 14/50\n",
      " - 67s - loss: 0.3574 - acc: 0.8408 - val_loss: 0.3555 - val_acc: 0.8462\n",
      "Epoch 15/50\n",
      " - 67s - loss: 0.3553 - acc: 0.8396 - val_loss: 0.3400 - val_acc: 0.8450\n",
      "Epoch 16/50\n",
      " - 67s - loss: 0.3564 - acc: 0.8387 - val_loss: 0.3426 - val_acc: 0.8469\n",
      "Epoch 17/50\n",
      " - 68s - loss: 0.3452 - acc: 0.8423 - val_loss: 0.3419 - val_acc: 0.8456\n",
      "Epoch 18/50\n",
      " - 67s - loss: 0.3432 - acc: 0.8491 - val_loss: 0.3651 - val_acc: 0.8344\n",
      "Epoch 19/50\n",
      " - 68s - loss: 0.3452 - acc: 0.8448 - val_loss: 0.3430 - val_acc: 0.8400\n",
      "Epoch 20/50\n",
      " - 67s - loss: 0.3315 - acc: 0.8540 - val_loss: 0.3297 - val_acc: 0.8588\n",
      "Epoch 21/50\n",
      " - 67s - loss: 0.3423 - acc: 0.8493 - val_loss: 0.3492 - val_acc: 0.8387\n",
      "Epoch 22/50\n",
      " - 67s - loss: 0.3385 - acc: 0.8459 - val_loss: 0.3061 - val_acc: 0.8594\n",
      "Epoch 23/50\n",
      " - 67s - loss: 0.3336 - acc: 0.8497 - val_loss: 0.3337 - val_acc: 0.8525\n",
      "Epoch 24/50\n",
      " - 67s - loss: 0.3286 - acc: 0.8526 - val_loss: 0.3180 - val_acc: 0.8562\n",
      "Epoch 25/50\n",
      " - 67s - loss: 0.3198 - acc: 0.8590 - val_loss: 0.3448 - val_acc: 0.8569\n",
      "Epoch 26/50\n",
      " - 67s - loss: 0.3259 - acc: 0.8551 - val_loss: 0.3419 - val_acc: 0.8450\n",
      "Epoch 27/50\n",
      " - 67s - loss: 0.3151 - acc: 0.8595 - val_loss: 0.3315 - val_acc: 0.8462\n",
      "Epoch 28/50\n",
      " - 67s - loss: 0.3255 - acc: 0.8523 - val_loss: 0.3210 - val_acc: 0.8600\n",
      "Epoch 29/50\n",
      " - 67s - loss: 0.3183 - acc: 0.8594 - val_loss: 0.3228 - val_acc: 0.8512\n",
      "Epoch 30/50\n",
      " - 67s - loss: 0.3189 - acc: 0.8589 - val_loss: 0.3208 - val_acc: 0.8594\n",
      "Epoch 31/50\n",
      " - 67s - loss: 0.3166 - acc: 0.8575 - val_loss: 0.3460 - val_acc: 0.8506\n",
      "Epoch 32/50\n",
      " - 67s - loss: 0.3200 - acc: 0.8545 - val_loss: 0.3089 - val_acc: 0.8581\n",
      "Epoch 33/50\n",
      " - 67s - loss: 0.3169 - acc: 0.8603 - val_loss: 0.3337 - val_acc: 0.8569\n",
      "Epoch 34/50\n",
      " - 67s - loss: 0.3183 - acc: 0.8565 - val_loss: 0.2949 - val_acc: 0.8656\n",
      "Epoch 35/50\n",
      " - 67s - loss: 0.3052 - acc: 0.8648 - val_loss: 0.3092 - val_acc: 0.8606\n",
      "Epoch 36/50\n",
      " - 67s - loss: 0.3101 - acc: 0.8626 - val_loss: 0.3162 - val_acc: 0.8512\n",
      "Epoch 37/50\n",
      " - 67s - loss: 0.3115 - acc: 0.8604 - val_loss: 0.2944 - val_acc: 0.8731\n",
      "Epoch 38/50\n",
      " - 67s - loss: 0.3074 - acc: 0.8636 - val_loss: 0.2860 - val_acc: 0.8794\n",
      "Epoch 39/50\n",
      " - 67s - loss: 0.3074 - acc: 0.8625 - val_loss: 0.2957 - val_acc: 0.8619\n",
      "Epoch 40/50\n",
      " - 67s - loss: 0.3028 - acc: 0.8655 - val_loss: 0.3316 - val_acc: 0.8550\n",
      "Epoch 41/50\n",
      " - 67s - loss: 0.3018 - acc: 0.8661 - val_loss: 0.3004 - val_acc: 0.8644\n",
      "Epoch 42/50\n",
      " - 68s - loss: 0.3104 - acc: 0.8584 - val_loss: 0.3231 - val_acc: 0.8500\n",
      "Epoch 43/50\n",
      " - 67s - loss: 0.3029 - acc: 0.8671 - val_loss: 0.2707 - val_acc: 0.8744\n",
      "Epoch 44/50\n",
      " - 67s - loss: 0.2963 - acc: 0.8701 - val_loss: 0.2937 - val_acc: 0.8750\n",
      "Epoch 45/50\n",
      " - 67s - loss: 0.3062 - acc: 0.8605 - val_loss: 0.2896 - val_acc: 0.8812\n",
      "Epoch 46/50\n",
      " - 68s - loss: 0.3005 - acc: 0.8677 - val_loss: 0.2815 - val_acc: 0.8638\n",
      "Epoch 47/50\n",
      " - 67s - loss: 0.2930 - acc: 0.8707 - val_loss: 0.2798 - val_acc: 0.8794\n",
      "Epoch 48/50\n",
      " - 67s - loss: 0.2995 - acc: 0.8673 - val_loss: 0.2892 - val_acc: 0.8744\n",
      "Epoch 49/50\n",
      " - 67s - loss: 0.2951 - acc: 0.8677 - val_loss: 0.2861 - val_acc: 0.8775\n",
      "Epoch 50/50\n",
      " - 67s - loss: 0.2989 - acc: 0.8688 - val_loss: 0.3335 - val_acc: 0.8569\n"
     ]
    }
   ],
   "source": [
    "callbacks = [ tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0)\n",
    "             #, ModelCheckpoint('video_3_512_VGG_no_drop.h5', monitor='val_loss', save_best_only=True, verbose=0) \n",
    "            ]\n",
    "with tf.device('/gpu:0'):\n",
    "    model.fit_generator(train_generator, workers=-1, \n",
    "                    steps_per_epoch=400, \n",
    "                    epochs=50, \n",
    "                    verbose=2,\n",
    "                    #callbacks=callbacks,\n",
    "                    use_multiprocessing=True,\n",
    "                    validation_data=test_generator,\n",
    "                    validation_steps=100\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('cnn_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
