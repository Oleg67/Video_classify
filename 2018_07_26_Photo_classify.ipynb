{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.5\n",
      "3.4.1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "print np.__version__\n",
    "print cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/oleg/EnkeSystem\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2018_07_17_Photo_classify.ipynb',\n",
       " 'video_y_Res.npy',\n",
       " '.ipynb_checkpoints',\n",
       " 'Oleg resume Machine learning.pdf',\n",
       " 'video_s112',\n",
       " 'video_x_Res.jpg',\n",
       " 'df_sorted.csv',\n",
       " '2018_07_25_Photo_classify.ipynb',\n",
       " '2018_07_19_Video_preperation.ipynb',\n",
       " 'video_gray',\n",
       " 'read_from_url_nielsen_sorted.ipynb',\n",
       " 'creds.docx',\n",
       " 'Different Ways People Walk Up Stairs.mp4',\n",
       " 'Oleg Yudin Consulting Agreement.docx',\n",
       " 'isrcs_none_response.csv',\n",
       " '2018_07_26_Photo_classify.ipynb',\n",
       " 'train_test_image.pkl',\n",
       " 'df_response.csv',\n",
       " 'bad_seperated_by_black.mp4',\n",
       " 'Oleg Yudin_NDA.docx',\n",
       " 'video_s_dif',\n",
       " 'video',\n",
       " 'check_isrc_request.ipynb',\n",
       " '2018_07_15_Video_classify_keras.ipynb',\n",
       " 'video_s',\n",
       " '2018_07_16_Video_classify_keras.ipynb',\n",
       " 'video_x_Res.npy',\n",
       " 'isrcs_error.csv',\n",
       " 'isrc_request.py',\n",
       " '2018_07_17_Video_preperation.ipynb',\n",
       " 'colunms_names.csv',\n",
       " 'good.jpg',\n",
       " 'good_seperated_by_black.mp4',\n",
       " 'Big Machine Radio Analysis 070118.xlsm',\n",
       " 'isrc_request.pyc',\n",
       " 'video_seg',\n",
       " 'video_data.pkl',\n",
       " 'Untitled.ipynb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print os.getcwd()\n",
    "os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CreateListofImages(folder, max_length=100, f_lists=np.array([]), period=1):\n",
    "    \n",
    "\n",
    "    \n",
    "    f_list = np.sort(os.listdir(os.path.join(os.getcwd(), folder)))\n",
    "    f_list = np.vectorize(lambda x: os.path.join(os.getcwd(), folder, x))(f_list)\n",
    "    ind_mask = np.arange(len(f_list)) % period == 0\n",
    "    f_list = f_list[ind_mask]\n",
    "    \n",
    "    f_size = len(f_list)\n",
    "    if f_size  < max_length:\n",
    "        f_list = np.sort(np.random.choice(f_list, size=max_length))\n",
    "        return np.append(f_lists, f_list)\n",
    "    j = 0\n",
    "    for i in range(f_size - max_length):\n",
    "        f_lists = np.append(f_lists, f_list[i:max_length+i])\n",
    "        \n",
    "    return f_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomCreateListofImages(folder, max_length=50, n_folders=10):\n",
    "    \n",
    "    \n",
    "    f_list = np.sort(os.listdir(os.path.join(os.getcwd(), folder)))\n",
    "    f_list = np.vectorize(lambda x: os.path.join(os.getcwd(), folder, x))(f_list)\n",
    "        \n",
    "    return np.sort(np.random.choice(f_list, size=(n_folders,max_length)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def periodCreateListofImages(folder, period=2):\n",
    "    \n",
    "    f_list = np.sort(os.listdir(os.path.join(os.getcwd(), folder)))\n",
    "    f_list = np.vectorize(lambda x: os.path.join(os.getcwd(), folder, x))(f_list)\n",
    "    ind_mask = np.arange(len(f_list)) % period == 0\n",
    "    \n",
    "    return f_list[ind_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CreateListofImagesfromList(f_list, max_length=50, f_lists=np.array([])):\n",
    "    \n",
    "    \n",
    "    f_size = len(f_list)\n",
    "    if f_size  < max_length:\n",
    "        f_list = np.sort(np.random.choice(f_list, size=max_length))\n",
    "        return np.append(f_lists, f_list)\n",
    "    \n",
    "    for i in range(f_size - max_length):\n",
    "        f_lists = np.append(f_lists, f_list[i:max_length+i])\n",
    "        \n",
    "    return f_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def folder_list(folders_list):\n",
    "    \n",
    "    list_files = np.array([])\n",
    "    for f in folders_list:\n",
    "        f = os.path.join(folders_list, f)\n",
    "        list_files = np.append(list_files, \n",
    "                np.sort(np.vectorize(lambda x: os.path.join(f, x))(os.listdir(f))))\n",
    "    \n",
    "    return list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Create_List_Images_for_train_test(folder, test_size=0.15, y_label=1):\n",
    "    \n",
    "    \n",
    "    f_list = np.sort(os.listdir(os.path.join(os.getcwd(), folder)))\n",
    "    f_list = np.vectorize(lambda x: os.path.join(os.getcwd(), folder, x))(f_list)\n",
    "    _n_train = int(len(f_list) * test_size)\n",
    "    _train_list = f_list[: len(f_list) -  _n_train]\n",
    "    _test_list = f_list[len(f_list) -  _n_train :]\n",
    "    \n",
    "            \n",
    "    return folder_list(_train_list), folder_list(_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Create_Folders_for_train_test(folder, test_size=0.15, y_label=1):\n",
    "    \n",
    "    _train_list = list()\n",
    "    _test_list = list()\n",
    "    \n",
    "    for fd in os.listdir(folder):\n",
    "        if fd in ['train', 'test']:\n",
    "            continue\n",
    "        f_list = np.sort(os.listdir(os.path.join(folder,fd)))\n",
    "        \n",
    "        _n_train = int(len(f_list) * test_size)\n",
    "        if not os.path.exists(os.path.join(folder, 'train')):\n",
    "                os.mkdir(os.path.join(os.getcwd(), folder, 'train'))\n",
    "        if not os.path.exists(os.path.join(os.getcwd(), folder, 'test')):\n",
    "                os.mkdir(os.path.join(os.getcwd(), folder, 'test'))\n",
    "\n",
    "\n",
    "        for f in f_list[: len(f_list) -  _n_train]:\n",
    "            shutil.copytree(os.path.join(os.getcwd(), folder, fd, f), os.path.join(os.getcwd(), folder, 'train', fd, f))\n",
    "        #_train_list.append(np.vectorize(lambda x: os.path.join(os.getcwd(), folder, 'train', fd, x))\n",
    "        #        (f_list[: len(f_list) -  _n_train]))\n",
    "                    #_test_list.append(np.vectorize(lambda x: os.path.join(os.getcwd(), folder, 'test', fd, x))\n",
    "        #        (f_list[len(f_list) -  _n_train :]))\n",
    "        for f in f_list[len(f_list) -  _n_train :]:\n",
    "            shutil.copytree(os.path.join(os.getcwd(), folder, fd, f), os.path.join(os.getcwd(), folder, 'test', fd, f))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create_Folders_for_train_test('video_s', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oleg/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/oleg/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#libraries\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(lr=1e-4, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen_tr = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #samplewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    #samplewise_std_normalization=True,\n",
    "    #rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    #rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/oleg/EnkeSystem'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'train']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/home/oleg/EnkeSystem/video_seg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35770 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen_tr.flow_from_directory(\n",
    "    'video_seg/train',\n",
    "    \n",
    "    target_size=(112, 112),\n",
    "    color_mode='grayscale',\n",
    "    classes=None,\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    save_prefix='',\n",
    "    save_format='png',\n",
    "    follow_links=False,\n",
    "    interpolation='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen_ts = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #samplewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    #samplewise_std_normalization=True,\n",
    "    #rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    #rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3225 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = datagen_ts.flow_from_directory(\n",
    "    'video_seg/test',\n",
    "    \n",
    "    target_size=(112, 112),\n",
    "    color_mode='grayscale',\n",
    "    classes=None,\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    save_prefix='',\n",
    "    save_format='png',\n",
    "    follow_links=False,\n",
    "    interpolation='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "#num_classes = 1\n",
    "epochs = 100\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(4, (3,3), \n",
    "                 activation='relu',\n",
    "                padding='same',\n",
    "                input_shape=(112,112,1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=4))\n",
    "#model.add(tf.keras.layers.Conv2D(4, (3,3), activation='relu'))\n",
    "#model.add(tf.keras.layers.MaxPooling2D(pool_size=4))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(1, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 4)       40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 28, 28, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 28, 4)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 1,869,353\n",
      "Trainable params: 1,869,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\n",
      " - 21s - loss: 7.5040 - acc: 0.5293 - val_loss: 12.7453 - val_acc: 0.2005\n",
      "Epoch 2/50\n",
      "\n",
      " - 22s - loss: 7.4797 - acc: 0.5308 - val_loss: 12.7513 - val_acc: 0.2002\n",
      "Epoch 3/50\n",
      " - 22s - loss: 7.5741 - acc: 0.5249 - val_loss: 12.7413 - val_acc: 0.2008\n",
      "Epoch 4/50\n",
      " - 23s - loss: 7.5203 - acc: 0.5283 - val_loss: 12.7625 - val_acc: 0.1995\n",
      "Epoch 5/50\n",
      " - 23s - loss: 7.4894 - acc: 0.5302 - val_loss: 12.7432 - val_acc: 0.2007\n",
      "Epoch 6/50\n",
      " - 22s - loss: 7.5135 - acc: 0.5287 - val_loss: 12.7438 - val_acc: 0.2006\n",
      "Epoch 7/50\n",
      " - 24s - loss: 7.5099 - acc: 0.5289 - val_loss: 12.7532 - val_acc: 0.2000\n",
      "Epoch 8/50\n",
      " - 23s - loss: 7.4830 - acc: 0.5306 - val_loss: 12.7550 - val_acc: 0.1999\n",
      "Epoch 9/50\n",
      " - 23s - loss: 7.5383 - acc: 0.5272 - val_loss: 12.7376 - val_acc: 0.2010\n",
      "Epoch 10/50\n",
      " - 22s - loss: 7.5003 - acc: 0.5295 - val_loss: 12.7669 - val_acc: 0.1992\n",
      "Epoch 11/50\n",
      " - 23s - loss: 7.5278 - acc: 0.5278 - val_loss: 12.7413 - val_acc: 0.2008\n",
      "Epoch 12/50\n",
      " - 23s - loss: 7.5019 - acc: 0.5294 - val_loss: 12.7444 - val_acc: 0.2006\n",
      "Epoch 13/50\n",
      " - 23s - loss: 7.4887 - acc: 0.5303 - val_loss: 12.7503 - val_acc: 0.2002\n",
      "Epoch 14/50\n",
      " - 24s - loss: 7.4950 - acc: 0.5299 - val_loss: 12.7544 - val_acc: 0.2000\n",
      "Epoch 15/50\n",
      " - 24s - loss: 7.5363 - acc: 0.5273 - val_loss: 12.7463 - val_acc: 0.2005\n",
      "Epoch 16/50\n",
      " - 24s - loss: 7.5400 - acc: 0.5270 - val_loss: 12.7532 - val_acc: 0.2000\n",
      "Epoch 17/50\n",
      " - 23s - loss: 7.4999 - acc: 0.5296 - val_loss: 12.7463 - val_acc: 0.2005\n",
      "Epoch 18/50\n",
      " - 23s - loss: 7.4922 - acc: 0.5300 - val_loss: 12.7457 - val_acc: 0.2005\n",
      "Epoch 19/50\n",
      " - 22s - loss: 7.5297 - acc: 0.5277 - val_loss: 12.7738 - val_acc: 0.1988\n"
     ]
    }
   ],
   "source": [
    "callbacks = [ tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0)\n",
    "             #, ModelCheckpoint('video_3_512_VGG_no_drop.h5', monitor='val_loss', save_best_only=True, verbose=0) \n",
    "            ]\n",
    "with tf.device('/gpu:0'):\n",
    "    model.fit_generator(train_generator, workers=8, \n",
    "                    steps_per_epoch=1000, \n",
    "                    epochs=50, \n",
    "                    verbose=2,\n",
    "                    callbacks=callbacks,\n",
    "                    use_multiprocessing=True,\n",
    "                    validation_data=test_generator,\n",
    "                    validation_steps=800\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tf.keras.layers import Conv2D, MaxPooling2D, Input, Dense\n",
    "\n",
    "input_img = Input(shape=(224, 224, 1))\n",
    "\n",
    "tower_1 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)\n",
    "tower_1 = Conv2D(64, (3, 3), padding='same', activation='relu')(tower_1)\n",
    "\n",
    "tower_2 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)\n",
    "tower_2 = Conv2D(64, (5, 5), padding='same', activation='relu')(tower_2)\n",
    "\n",
    "tower_3 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(input_img)\n",
    "tower_3 = Conv2D(64, (1, 1), padding='same', activation='relu')(tower_3)\n",
    "\n",
    "output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train.reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model.fit(X_train.reshape(36213, 224, 224,1), y_train, batch_size=32, epochs=12, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_tr, y_tr, batch_size=1, epochs=3, var_list=train_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
